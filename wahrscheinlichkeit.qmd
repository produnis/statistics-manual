---
title: Wahrscheinlichkeit
---

Die deskriptive Statistik bietet Methoden zur Beschreibung der in der Probe gemessenen Variablen und ihrer Beziehungen, ermöglicht jedoch  keine Schlüsse aus dieser Probe auf die Grundgesamtheit.

Jetzt ist es Zeit, von der Stichprobe zur Grundgesamtheit zu gelangen, und die Brücke dafür ist die **Wahrscheinlichkeitstheorie**.

Bitte beachten Sie, dass die Stichprobe nur begrenzte Informationen über die Grundgesamtheit hat, und um gültige Schlüsse für diese zu ziehen, muss die Probe *repräsentativ* sein. Dies ist strenggenommen nur bei Zufallsstichproben gegeben.

Die Wahrscheinlichkeitstheorie wird uns Werkzeuge bieten, um den Zufall in der Stichprobenziehung zu kontrollieren und das Vertrauensniveau der aus der Stichprobe gezogenen Schlüsse zu bestimmen.

## Experiment mit zufälligem Ergebnis

Die Untersuchung einer Eigenschaft der Grundgesamtheit erfolgt durch Experimente mit zufälligem Ergebnis.

::: {.callout-warning appearance="default"}
## Definition  "Zufallsexperiment"

Ein Zufallsexperiment ist ein Experiment, das zwei Bedingungen erfüllt:

1. Alle möglichen Ergebnisse sind bekannt.
2. Es ist unmöglich, das Ergebnis mit absoluter Sicherheit vorherzusagen.

:::

::: {.callout-tip appearance="default"}
## Beispiel: Glücksspiele

Glücksspiele sind typische Beispiele für Experimente mit zufälligem Ergebnis. Zum Beispiel ist das Werfen eines Würfels ein  solches Experiment, weil:

1. Der Satz der möglichen Ergebnisse bekannt ist: $\{1, 2, 3, 4, 5, 6\}$.
2. Bevor der Würfel geworfen wird ist es unmöglich das Ergebnis mit absoluter Sicherheit vorherzusagen.

:::


Ein weiteres Beispiel, das nichts mit Glücksspielen zu tun hat, ist die zufällige Auswahl einer Person aus einer menschlichen Grundgesamtheit und die Bestimmung ihrer Blutgruppe.

Grundsätzlich ist die Ziehung einer Stichprobe mittels einer Zufallsmethode ein Zufallsexperiment.

### Wahrscheinlichkeitsraum

::: {.callout-warning appearance="default"}
## Definition "Wahrscheinlichkeitsraum $\Omega$" 
Der Satz $\Omega$ der möglichen Ergebnisse eines Zufallsexperiments wird als Wahrscheinlichkeitsraum (Probabilitätsraum) bezeichnet.
:::

::: {.callout-tip appearance="default"}
## Beispiele für Probabilitätsräume:

- Beim Werfen einer Münze ist $\Omega =  \{Kopf, Zahl\}$.
- Beim Werfen eines Würfels ist $\Omega =  \{1, 2, 3, 4, 5, 6 \}$.
- Beim Blutgruppentest einer zufällig ausgewählten Person ist $\Omega =  \{0, A, B, AB \}$.
- Bei der Körpergröße einer zufällig ausgewählten Person ist $\Omega=\mathbb{R}^+$.

:::

### Baumdiagramme

In Experimenten, bei denen mehr als eine Variable gemessen wird, kann die Bestimmung des Wahrscheinlichkeitsraums schwierig sein. In solchen Fällen ist es ratsam, ein Baumdiagramm zur Konstruktion des Probabilitätsraums zu verwenden.

In einem Baumdiagramm wird jede Variable auf einer Ebene des Baums dargestellt und jeder mögliche Wert der Variablen als Zweig.

```{dot}
//| label: baumdiagramm
digraph bloodtype_tree {
    node [shape=box];

    root -> weiblich;
    root -> männlich;

    weiblich -> weiblich_0;
    weiblich -> weiblich_A;
    weiblich -> weiblich_B;
    weiblich -> weiblich_AB;

    weiblich_0 -> F0;
    weiblich_A -> FA;
    weiblich_B -> FB;
    weiblich_AB -> FAB;

    männlich -> männlich_0;
    männlich -> männlich_A;
    männlich -> männlich_B;
    männlich -> männlich_AB;

    männlich_0 -> M0;
    männlich_A -> MA;
    männlich_B -> MB;
    männlich_AB -> MAB;

    // leaf labels
    root [label=" "];
    weiblich_0 [label="0"];
    weiblich_A [label="A"];
    weiblich_B [label="B"];
    weiblich_AB [label="AB"];
    männlich_0 [label="0"];
    männlich_A [label="A"];
    männlich_B [label="B"];
    männlich_AB [label="AB"];
    
    
    
    F0 [label="(weiblich, 0)"];
    FA [label="(weiblich, A)"];
    FB [label="(weiblich, B)"];
    FAB [label="(weiblich, AB)"];
    
    M0 [label="(männlich, 0)"];
    MA [label="(männlich, A)"];
    MB [label="(männlich, B)"];
    MAB [label="(männlich, AB)"];

    // optional: rank same level nodes
    { rank=same; weiblich männlich }
    { rank=same; weiblich_0 weiblich_A weiblich_B weiblich_AB männlich_0 männlich_A männlich_B männlich_AB }
    { rank=same; F0 FA FB FAB M0 MA MB MAB }

    // optional: labels for levels (simulated)
    labelloc="t";
    label="Geschlecht → Blutgruppe → Paar (Ω)";
    fontsize=26;
}

```



### Zufallsereignis

::: {.callout-warning appearance="default"}
## Definition Zufallsereignis

Ein zufälliges Ereignis ist jede Teilmenge des Probabilitätsraums $\Omega$ eines Zufallsexperimentes.

:::


Es gibt verschiedene Arten von Ereignissen:

- unmögliches Ereignis: Dies ist das Ereignis ohne Elemente  $\emptyset$. Es hat keine Chance einzutreten.
- elementare Ereignisse: Dies sind Ereignisse mit nur einem Element.
- zusammengesetzte Ereignisse: Dies sind Ereignisse mit zwei oder mehr Elementen.
- sicheres Ereignis: Dies ist das Ereignis, das den gesamten Probabilitätsraum $\Omega$ enthält. Es tritt immer ein.

## Mengentheorie

### Ereignisraum

::: {.callout-warning appearance="default"}
##  Definition 32 Ereignisraum

Gegeben einen Wahrscheinlichkeitsraum $\Omega$ eines Zufallsexperimentes, ist die Ereignismenge von $\Omega$ die Menge aller möglichen Ereignisse von $\Omega$ und wird mit $\mathcal{P}(\Omega)$ bezeichnet.
:::

::: {.callout-tip appearance="default"}
## Beispiel

Für den Probabilitätsraum $\Omega=\{a,b,c\}$ ist dessen Ereignismenge:

$$
\mathcal{P}(\Omega)=\left\{\emptyset, \{a\},\{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\}\right\}
$$
:::


### Ereignisoperationen

Da Ereignisse Teilmengen des Wahrscheinlichkeitsraums sind, haben wir mittels der Mengentheorie folgende Operationen an Ereignissen:

- Vereinigung
- Schnittmenge
- Komplementärmenge
- Differenzmenge

#### Vereinigung von Ereignissen

::: {.callout-warning appearance="default"}
## Definition "Vereinigungsereignis"

Gegeben zwei Ereignisse $A,B\subseteq \Omega$, ist die Vereinigung von $A$ und $B$, bezeichnet mit $A\cup B$, das Ereignis aller Elemente, die Mitglieder von $A$ oder $B$ oder beiden sind.

$$
A\cup B = \{x\,|\, x\in A\textrm{ oder }x\in B\}.
$$
:::


```{r}
#| engine: tikz
#| label: vereinigungsereignis
\begin{tikzpicture}
\def\firstcircle{(1.5,1.5) circle (1cm)}
\def\secondcircle{(2.5,1.5) circle (1cm)}

\fill[blue!30] \firstcircle;
\fill[blue!30] \secondcircle;
\draw (0,3) node[anchor=north east] {$\Omega$} rectangle (4,0);
\draw \firstcircle node[xshift=-0.9cm, yshift=0.9cm] {$A$};
\draw \secondcircle node[xshift=0.9cm, yshift=0.9cm] {$B$};

\node at (2,0.3) {$A\cup B$};
\end{tikzpicture}
```

Das Vereinigungsereignis  $A,B\subseteq \Omega$  tritt ein, wenn $A$ oder $B$ eintreten.



#### Schnittereignis

::: {.callout-warning appearance="default"}
## Definition "Schnittereignis"

Angenommen, wir haben zwei Ereignisse $A$ und $B$, die Teilmengen von $\Omega$ sind. Das Schnittereignis (*Intersection*) von $A$ und $B$, bezeichnet mit $A\cap B$, ist das Ereignis aller Elemente, die sowohl zu $A$ als auch zu $B$ gehören.

$$
A\cap B = \{x\,|\, x\in A\mbox{ und }x\in B\}.
$$
:::

```{r}
#| engine: tikz
#| label: schnittereignis
\begin{tikzpicture}
\def\firstcircle{(1.5,1.5) circle (1cm)}
\def\secondcircle{(2.5,1.5) circle (1cm)}

\begin{scope}
\clip \firstcircle;
\fill[blue!30] \secondcircle;
\end{scope}

\draw (0,3) node[anchor=north east] {$\Omega$} rectangle (4,0);
\draw \firstcircle node[xshift=-0.9cm, yshift=0.9cm] {$A$};
\draw \secondcircle node[xshift=0.9cm, yshift=0.9cm] {$B$};

\node at (2,1.5) {$A\cap B$};
\end{tikzpicture}
```


Das Ereignis $A\cap B$ tritt ein, wenn sowohl $A$ als auch $B$ eintreten.
Zwei Ereignisse sind **unmöglich**, wenn ihr Schnitt leer ist.


#### Komplementärereignis

::: {.callout-warning appearance="default"}
## Definition "Komplementärereignis"

Angenommen, wir haben ein Ereignis $A$, das eine Teilmenge von $\Omega$ ist. Das komplementäre oder gegensätzliche Ereignis zu $A$, bezeichnet mit $\overline A$, ist das Ereignis aller Elemente in $\Omega$ außer denjenigen, die zu $A$ gehören.

$$
\overline A = \{x\,|\, x\not\in A\}.
$$
:::

```{r}
#| engine: tikz
#| label: komplementaer
\begin{tikzpicture}
\def\circle{(1.5,1.5) circle (1cm)}
\def\rectangle{(4,0) rectangle (0,3)}

\begin{scope}[even odd rule]
\clip \circle (0,0) rectangle (4,3);
\fill[blue!30] \rectangle;
\end{scope}

\draw \rectangle node[anchor=north east] {$\Omega$};
\draw \circle node {$A$};
\node at (3,1.5) {$\overline A$};
\end{tikzpicture}
```

Das komplementäre Ereignis $\overline A$ tritt ein, wenn $A$ nicht eintritt.


#### Differenzereignis

::: {.callout-warning appearance="default"}
## Definition "Differenzereignis"

Gegeben sind zwei Ereignisse $A$ und $B$ als Teilmengen von $\Omega$. Die Differenz von $A$ und $B$, bezeichnet mit $A-B$, ist das Ereignis aller  Elemente, die zu $A$ gehören, aber nicht zu $B$.


$$
A-B = \{x\,|\, x\in A\mbox{ und }x\not\in B\} = A \cap \overline B.
$$
:::

```{r}
#| label: differenzereignis
#| engine: tikz
\begin{tikzpicture}
\def\firstcircle{(1.5,1.5) circle (1cm)}
\def\secondcircle{(2.5,1.5) circle (1cm)}

\begin{scope}[even odd rule]
\clip \secondcircle (0,0) rectangle (4,3);
\fill[blue!30] \firstcircle;
\end{scope}

\draw (0,3) node[anchor=north east] {$\Omega$} rectangle (4,0);
\draw \firstcircle node[xshift=-0.9cm, yshift=0.9cm] {$A$};
\draw \secondcircle node[xshift=0.9cm, yshift=0.9cm] {$B$};

\node[anchor=east] at (1.5,1.5) {$A-B$};
\end{tikzpicture}
```


Das Differenzereignis $A-B$ tritt ein, wenn $A$ eintritt, aber $B$ nicht.


#### Beispiel

::: {.callout-tip appearance="default"}
## Beispiel 

Der Ereignisraum beim Würfeln ist $\Omega=\{1,2,3,4,5,6\}$ und die Ereignisse sind 

- $A=\{2,4,6\}$ und 
- $B=\{1,2,3,4\}$, 

dann gilt:

- Die Vereinigungsmenge von $A$ und $B$ ist $A\cup B=\{1,2,3,4,6\}$.
- Die Schnittmenge von  $A$ und $B$ ist $A\cap B=\{2,4\}$.
- Das Komplement von $A$ ist $\overline A=\{1,3,5\}$
- Die Ereignisse $A$ und $\overline A$ schließen sich gegenseitig aus.
- Die Differenz von $A$ und $B$ ist $A-B=\{6\}$ und die Differenz von $B$ und $A$ ist $B-A=\{1,3\}$
:::


### Algebra

Sind die Ereignisse $A,B,C\subseteq \Omega$ gegeben, treffen die folgenden algebra'schen Eigenschaften zu:

- **Idempotenz:** $A\cup A=A,\quad A\cap A=A$ 
- **Kommutativität:**  $A\cup B=B\cup A,\quad A\cap B = B\cap A$
- **Assoziativität:**  $(A\cup B)\cup C = A\cup (B\cup C),\quad (A\cap B)\cap C = A\cap (B\cap C)$
- **Distributivität:** $(A\cup B)\cap C = (A\cap C)\cup (B\cap C),\quad (A\cap B)\cup C = (A\cup C)\cap (B\cup C)$
- **Neutrales Element:**  $A\cup \emptyset=A,\quad A\cap \Omega=A$
- **absorbierendes Element:**  $A\cup \Omega=\Omega,\quad A\cap \emptyset=\emptyset$
- **komplementäres symmetrisches Element** $A\cup \overline A = \Omega,\quad A\cap \overline A= \emptyset$ 
- **doppelte Negation:**  $\overline{\overline A} = A$
- **De Morgansche Gesetze:** $\overline{A\cup B} = \overline A\cap \overline B,\quad \overline{A\cap B} = \overline A\cup \overline B$






## Wahrscheinlichkeit

::: {.callout-warning appearance="default"}
## Defintion "Wahrscheinlichkeit" (nach Laplace)
Für ein Zufallsexperiment mit einem Ereignisraum $\Omega$, dessen Elemente alle gleich wahrscheinlich 
sind, ist die Wahrscheinlichkeit eines Ereignisses $A\subseteq \Omega$ der Quotient zwischen der Anzahl der Elemente von $A$ und der Anzahl der Elemente von $\Omega$

$$
P(A) = \frac{|A|}{|\Omega|} = \frac{\mbox{Anzahl gewünschter Ergebnisse}}{\mbox{Anzahl aller möglichen Ergebnisse}}
$$
:::

Diese Definition ist gut bekannt, hat aber wichtige Einschränkungen:

- Es wird verlangt, dass alle Elemente des Ereignisraums gleich wahrscheinlich sind (Gleichwahrscheinlichkeit).
- Sie kann nicht bei unendlichen großen Ereignisräumen angewendet werden.

::: {.callout-important appearance="default"}
## Vorsicht! 
Diese Bedingungen werden in vielen echten Experimenten nicht erfüllt.
:::



::: {.callout-tip appearance="default"}
## Beispiel
Angenommen, der Ereignisraum beim Werfen eines Würfels ist $\Omega=\{1,2,3,4,5,6\}$ und das Ereignis $A=\{2,4,6\}$, dann beträgt die Wahrscheinlichkeit von $A$

$$
P(A) = \frac{|A|}{|\Omega|} = \frac{3}{6} = 0.5.
$$

Allerdings ist es beim Ereignisraum der Blutgruppe einer zufällig ausgewählten Person $\Omega=\{O,A,B,AB\}$ nicht möglich, die klassische Definition zu verwenden, um die Wahrscheinlichkeit für Gruppe $A$ zu berechnen,

$$
P(A) \neq \frac{|A|}{|\Omega|} = \frac{1}{4} = 0.25,
$$

...weil Blutgruppen in der menschlichen Bevölkerung nicht *gleich* wahrscheinlich sind.

:::



### Häufigkeitswahrscheinlichkeit

::: {.callout-warning appearance="default"}
## Definition "Gesetz der großen Zahlen"
Wenn ein zufälliges Experiment eine große Anzahl von Malen wiederholt wird, nähert sich die relative 
Häufigkeit eines Ereignisses der Wahrscheinlichkeit des Ereignisses an.

:::

Die folgende Definition der Wahrscheinlichkeit basiert auf diesem Satz.

::: {.callout-warning appearance="default"}
## Definition "Frequenzwahrscheinlichkeit"
Gegeben ein Ereignisraum $\Omega$ eines reproduzierbaren zufälligen Experiments, beträgt die 
Wahrscheinlichkeit eines Ereignisses $A\subseteq \Omega$ die relative Häufigkeit des Ereignisses $A$ bei einer unbegrenzten Anzahl von Wiederholungen des Experiments.

$$
P(A) = lim_{n\rightarrow \infty}\frac{n_A}{n}
$$
:::



Auch diese Definition hat einige Nachteile:

- Sie berechnet eine *Schätzung* der realen Wahrscheinlichkeit.
- Die Wiederholung des Experiments muss unter identischen Bedingungen stattfinden.

::: {.callout-tip appearance="default"}
## Beispiel Münzwurf
Gegeben ist der Ereignisraum beim Werfen einer Münze $\Omega=\{Kopf, Zahl\}$. 
Wenn nach $100$ Würfen 54mal Kopf herauskam, beträgt die Wahrscheinlichkeit von $Kopf$
$$
P(Kopf) = \frac{n_{Kopf}}{n} = \frac{54}{100} = 0.54.
$$

:::

::: {.callout-tip appearance="default"}
## Beispiel Blutgruppen
Gegeben ist der Ereignisraum der Blutgruppe einer zufällig ausgewählten Person $\Omega=\{O,A,B,AB\}$. Wenn nach einer Zufallsstichprobe von 1.000  Personen 412 mit der Blutgruppe $A$ dabei waren, beträgt die Wahrscheinlichkeit von $A$

$$
P(A) = \frac{n_A}{n} = \frac{412}{1000} = 0.412.
$$
:::




### Axiomatische Wahrscheinlichkeit

::: {.callout-warning appearance="default"}
## Definition "Wahrscheinlichkeit" (nach Kolmogórov)
Gegeben ein Ereignisraum $\Omega$ eines zufälligen Experiments, ist eine  Wahrscheinlichkeitsfunktion eine Funktion, die jeden Ereigniswert $A\subseteq \Omega$ auf eine reelle Zahl $P(A)$ (bekannt als Wahrscheinlichkeit von $A$), abbildet und folgende Axiome erfüllt:

1. Die Wahrscheinlichkeit jedes Ereignisses ist nicht negativ, 
$$
P(A)\geq 0.
$$
2. Die Wahrscheinlichkeit des Ereignisraums beträgt 1,
$$
P(\Omega)=1
$$
3. Die Wahrscheinlichkeit der Vereinigung zweier inkompatibler Ereignisse ($A\cap B=\emptyset$) ist die Summe ihrer Wahrscheinlichkeiten
$$
P(A\cup B) = P(A)+P(B).
$$
:::


#### Eigenschaften der axiomatischen Wahrscheinlichkeit

Aus diesen Axiomen lassen sich einige wichtige Eigenschaften einer Wahrscheinlichkeitsfunktion ableiten.
Gegeben ein Ereignisruam $\Omega$ eines zufälligen Experiments und die Ereignisse $A,B\subseteq \Omega$, gelten folgende Eigenschaften:

1. $P(\overline A) = 1-P(A)$.
2. $P(\emptyset)= 0$.
3. Wenn $\ A\subseteq B\ $ dann $\ P(A)\leq P(B)$.
4. $P(A) \leq 1\ $. Das bedeutet $\ P(A)\in [0,1]$.
5. $P(A-B)=P(A)-P(A\cap B)$. 
6. $P(A\cup B)= P(A) + P(B) - P(A\cap B)$.
7. Wenn $\ A=\{e_1,\ldots,e_n\}\ $, und $\ e_i$ $i=1,\ldots,n\ $ Elementarereignisse sind, dann gilt
$$
P(A)=\sum_{i=1}^n P(e_i).
$$





### Wahrscheinlichkeitsinterpretation

Gemäß den vorherigen Axiomen ist die Wahrscheinlichkeit eines Ereignisses $A$ eine reelle Zahl $P(A)$, die stets im Bereich von 0 bis 1  liegt.

Auf gewisse Weise drückt diese Zahl die Glaubwürdigkeit des Ereignisses aus, d.h. die Chancen, dass das Ereignis $A$ in dem Experiment  eintritt. Daher gibt sie auch ein Maß für die *Unsicherheit* bezüglich des Ereignisses an.

- Die maximale Unsicherheit entspricht der Wahrscheinlichkeit $P(A) = 0,5\quad$ ($A$ und $\overline A$ haben die gleiche Chance, einzutreten).
- Die minimale Unsicherheit entspricht der Wahrscheinlichkeit $P(A) = 1\quad$ ($A$ wird mit absoluter Sicherheit eintreten) und $P(A) = 0\quad$ ($A$ wird  mit absoluter Sicherheit nicht eintreten). 

Wenn $P(A)$ näher bei $0$ als bei $1$ liegt, sind die Chancen, dass $A$ nicht eintritt, größer als die 
Chancen, dass $A$ eintritt. 

Im Gegensatz dazu, wenn $P(A)$ näher bei $1$ als bei $0$ liegt, sind die Chancen, dass $A$ eintritt, größer als die Chancen, dass $A$ nicht eintritt.









## bedingte Wahrscheinlichkeit 

Gelegentlich können wir bereits vor der Durchführung eines Experiments einige Informationen darüber erhalten. Üblicherweise wird diese Information als Ereignis $B$ des gleichen Ereignisraums gegeben, von dem wir wissen, dass es wahr ist, bevor wir das Experiment durchführen.

In einem solchen Fall werden wir sagen, dass $B$ ein *konditionierendes Ereignis* ist und die Wahrscheinlichkeit eines anderen Ereignisses $A$ als *bedingte Wahrscheinlichkeit* bezeichnen. Diese wird  als $P(A|B)$ ausgedrückt.

Dies muss als "Wahrscheinlichkeit von $A$ unter der Bedingung $B$" oder "Wahrscheinlichkeit von $A$ gegeben $B$" gelesen werden.

::: {.callout-tip appearance="default"}
## Beispiel

Konditionierende Ereignisse ändern normalerweise den Ereignisraum und damit die Wahrscheinlichkeiten der Ereignisse. Angenommen, wir haben eine Stichprobe von 100 Frauen und 100 Männern mit den folgenden Häufigkeiten:

$$
\begin{array}{|c|c|c|}
 & \mbox{Nichtraucher} & \mbox{Raucher} \\ \hline
 \rowcolor{coral}\color{white} \mbox{Frauen} & \color{white}80 & \color{white}20 \\ \hline
 \mbox{Männer} & 60 & 40 \\ \hline
\end{array}
$$

Dann beträgt die Wahrscheinlichkeit, ein Raucher zu sein, basierend auf der gesamten Probe:

$$
P(\mbox{Raucher})= \frac{60}{200}=0.3.
$$

Wenn wir jedoch wissen, dass die Person eine Frau ist, wird die Stichprobe auf die erste Zeile reduziert und die Wahrscheinlichkeit, eine Raucherin zu sein, beträgt:

$$
P(\mbox{Raucherin}|\mbox{Frau})=\frac{20}{100}=0.2.
$$

:::




::: {.callout-warning appearance="default"}
## Definition "bedingte Wahrscheinlichkeit"
Gegeben ist ein Ereignisraum $\Omega$ eines zufälligen Experiments und zwei Ereignisse $A,B\subseteq \Omega$, so ist die Wahrscheinlichkeit von $A$ unter der Bedingung, dass $B$ eintritt:
$$
P(A|B) = \frac{P(A\cap B)}{P(B)},
$$
solange $P(B)\neq 0$.
:::

Diese Definition ermöglicht es, bedingte Wahrscheinlichkeiten zu berechnen, ohne den ursprünglichen Ereignisraum zu ändern.

::: {.callout-tip appearance="default"}
## Beispiel
In dem vorherigen Beispiel ist die bedingte Wahrscheinlichkeit, dass eine Person Raucher und weiblich ist:

$$
P(\mbox{Raucher}|\mbox{weiblich})= \frac{P(\mbox{Raucher}\cap \mbox{weiblich})}{P(\mbox{weiblich})} = \frac{20/200}{100/200}=\frac{20}{100}=0.2.
$$
:::




### Wahrscheinlichkeit des Schnittmengen-Ereignisses:

Aus der Definition der bedingten Wahrscheinlichkeit kann die Formel für die Wahrscheinlichkeit der Schnittmenge zweier Ereignisse abgeleitet werden:

$$
P(A\cap B) = P(A)P(B|A) = P(B)P(A|B).
$$


::: {.callout-tip appearance="default"}
## Beispiel: Brustkrebs 
In einer Bevölkerung gibt es 30 % Raucherinnen und wir wissen, dass 40 % dieser Raucher Krebs haben. Die Wahrscheinlichkeit, dass eine zufällig ausgewählte Person raucht und Krebs hat, beträgt:

$$
P(\mbox{Raucher}\cap \mbox{Krebs})= P(\mbox{raucher})P(\mbox{Krebs}|\mbox{Raucher}) =
0.3\times 0.4 = 0.12.
$$
:::





### Unabhängigkeit der Ereignisse

Manchmal ändert das bedingende Ereignis die ursprüngliche Wahrscheinlichkeit des Hauptereignisses nicht.

::: {.callout-warning appearance="default"}
## Definition "Unabhängige Ereignisse"
Gegeben einen Ereignisraum $\Omega$ eines zufälligen Experiments, sind zwei Ereignisse $A,B\subseteq \Omega$ *unabhängig*, wenn die Wahrscheinlichkeit von $A$ sich nicht ändert, wenn sie durch $B$ bedingt ist, und umgekehrt, d.h.,

$$
P(A|B) = P(A) \quad \mbox{und} \quad P(B|A)=P(B),
$$
wenn $P(A)\neq 0\ $ und $\ P(B)\neq 0$.
:::


Das bedeutet, dass das Eintreten eines Ereignisses keine relevante Information liefert, um die Unsicherheit des anderen Ereignisses zu ändern.

Wenn zwei Ereignisse unabhängig sind, ist die Wahrscheinlichkeit ihrer Schnittmenge gleich dem Produkt ihrer Wahrscheinlichkeiten,

$$
P(A\cap B) = P(A)\cdot P(B)
$$


::: {.callout-tip appearance="default"}
## Beispiel: Münzwurf

Der Ereignisraum für den doppelten Wurf einer Münze ist $\Omega=\{(K,K),(K,Z),(Z,K),(Z,Z)\}$ und alle Elemente sind gleich wahrscheinlich, wenn die Münze fair ist. Daher haben wir durch die klassische Definition der Wahrscheinlichkeit

$$
P((K,K)) = \frac{1}{4} = 0.25.
$$
Wenn wir $K_1=\{(K,K),(K,Z)\}$, d.h., Kopf beim ersten Wurf, und $H_2=\{(K,K),(Z,K)\}$ nennen, d.h., Kopf beim zweiten Wurf, können wir das gleiche Ergebnis erhalten, indem wir davon ausgehen, dass diese Ereignisse unabhängig sind,

$$
P(K,K)= P(K_1\cap K_2) = P(K_1)\cdot P(K_2) = \frac{2}{4}\cdot\frac{2}{4}=\frac{1}{4}=0.25.
$$
:::







## Wahrscheinlichkeitsraum

::: {.callout-warning appearance="default"}
## Definition "Wahrscheinlichkeitsraum"

Ein Wahrscheinlichkeitsraum eines zufälligen Experiments ist ein Tripel $(\Omega,\mathcal{F},P)$ 
wobei

- $\mathbf{\Omega}\ $ der Ereignisraum des Experiments ist.
- $\mathbf{\mathcal{F}}\ $  eine Menge von Ereignissen des Experiments ist.
- $\mathbf{P}\ $  eine Wahrscheinlichkeitsfunktion ist.

:::

Wenn wir die Wahrscheinlichkeiten aller Elemente von $\Omega$ kennen, können wir leicht den Wahrscheinlichkeitsraum konstruieren und die Wahrscheinlichkeit jedes Ereignisses in $\mathcal{F}$ berechnen.





### Konstruktion des Wahrscheinlichkeitsraums

Um die Wahrscheinlichkeit jedes möglichen (elementaren) Ereignisses zu berechnen, können wir ein Baumdiagramm verwenden. Dabei gelten folgende Regeln:

1. Jede Kante im Baum erhält eine Wahrscheinlichkeit. Diese gibt an, wie wahrscheinlich der jeweilige Wert unter der Bedingung der vorherigen Knoten ist.
2.  Die Wahrscheinlichkeit eines vollständigen Pfads (also eines Ereignisses ganz am Ende des Baums) ergibt sich, indem man die Wahrscheinlichkeiten aller Kanten entlang dieses Pfads miteinander multipliziert – vom Start (Wurzel) bis zum Ende (Blatt).

```{r}
#| engine: tikz
#| label: probTree1
\begin{tikzpicture}[
  grow'=right,
  level 1/.style ={level distance=2cm, sibling distance=1.6cm, parent anchor=east, child anchor=west},
  level 2/.style ={level distance=2.5cm, sibling distance=0.8cm},
  level 3/.style ={level distance=1.5cm, sibling distance=0.8cm, dashed},
  level 4/.style ={level distance=3.5cm, sibling distance=0.8cm, dashed},
  prob/.style={font=\footnotesize,above}
]

% Baumstruktur
\node (root) {}
  child {node (x1) {$x_1$}
    child {node (y1x1) {$y_1$}
      child {node (xy1x1) {$(x_1,y_1)$} 
        child {node (pxy1x1) {$P(x_1\cap y_1)$} edge from parent node[prob] {$P(x_1)P(y_1|x_1)$}}
      }
      edge from parent node[prob] {$P(y_1|x_1)$}
    }
    child {node (y2x1) {$y_2$}
      child {node (xy2x1) {$(x_1,y_2)$} 
        child {node (pxy2x1) {$P(x_1\cap y_2)$} edge from parent node[prob] {$P(x_1)P(y_2|x_1)$}}
      }
      edge from parent node[prob,below] {$P(y_2|x_1)$}
    }
    edge from parent node[prob] {$P(x_1)$}
  }
  child {node (x2) {$x_2$}
    child {node (y1x2) {$y_1$}
      child {node (xy1x2) {$(x_2,y_1)$} 
        child {node (pxy1x2) {$P(x_2\cap y_1)$} edge from parent node[prob] {$P(x_2)P(y_1|x_2)$}}
      }
      edge from parent node[prob] {$P(y_1|x_2)$}
    }
    child {node (y2x2) {$y_2$}
      child {node (xy2x2) {$(x_2,y_2)$}
        child {node (pxy2x2) {$P(x_2\cap y_2)$} edge from parent node[prob] {$P(x_2)P(y_2|x_2)$}}
      }
      edge from parent node[prob,below] {$P(y_2|x_2)$}
    }
    edge from parent node[prob,below] {$P(x_2)$}
  };

% Beschriftung über den Ebenen (ohne scope)
\node[text width=3.5cm, align=center] at ([yshift=1cm]pxy1x1.north) {Wahrscheinlichkeit};
\node[font=\bfseries, text width=2cm, align=center] at ([yshift=1cm]xy1x1.north) {$\Omega$};
\node[font=\bfseries, text width=2cm, align=center] at ([yshift=1cm]y1x1.north) {$Y$};
\node[font=\bfseries, text width=2cm, align=center] at ([yshift=1cm]x1.north) {$X$};

\end{tikzpicture}

```



### Wahrscheinlichkeitsbaum mit abhängigen Variablen

::: {.callout-tip appearance="default"}
## Beispiel:  Rauchen und Krebs:

In einer Population gibt es 30 % Raucher und wir wissen, dass 40 % der Raucher Krebs haben, während nur 10 % der Nichtraucher an Krebs erkrankt sind. Der Wahrscheinlichkeitsbaum des Wahrscheinlichkeitsraums des zufälligen Experiments, das darin besteht, eine zufällig ausgewählte Person auszuwählen und die Variablen Rauchen und Brustkrebs zu messen, ist unten dargestellt.

```{r}
#| label: probTreeRauchen
#| engine: tikz
\begin{tikzpicture}[
  grow'=right,
  level 1/.style ={level distance=2cm, sibling distance=1.6cm, parent anchor=east, child anchor=west},
  level 2/.style ={level distance=2cm, sibling distance=0.8cm},
  level 3/.style ={level distance=1.5cm, sibling distance=0.8cm, dashed},
  level 4/.style ={level distance=3cm, sibling distance=0.8cm, dashed},
  prob/.style={font=\footnotesize,above}
]

\node (root) {}
  child {node (S) {R}
    child {node (C1) {K}
      child {node (SC) {(R,K)}
        child {node (PSC) {$0.12$} edge from parent node[prob] {$0.3\cdot 0.4$}}
      }
      edge from parent node[prob] {$0.4$}
    }
    child {node (nC1) {$\overline{\mbox{K}}$}
      child {node (SnC) {(R,$\overline{\mbox{K}}$)}
        child {node (PSnC) {$0.18$} edge from parent node[prob] {$0.3\cdot 0.6$}}
      }
      edge from parent node[prob,below] {$0.6$}
    }
    edge from parent node[prob] {$0.3$}
  }
  child {node (nS) {$\overline{\mbox{R}}$}
    child {node (C2) {K}
      child {node (nSC) {($\overline{\mbox{R}}$,K)}
        child {node (PnSC) {$0.07$} edge from parent node[prob] {$0.7\cdot 0.1$}}
      }
      edge from parent node[prob] {$0.1$}
    }
    child {node (nC2) {$\overline{\mbox{K}}$}
      child {node (nSnC) {($\overline{\mbox{R}}$,$\overline{\mbox{K}}$)}
        child {node (PnSnC) {$0.63$} edge from parent node[prob] {$0.7\cdot 0.9$}}
      }
      edge from parent node[prob,below] {$0.9$}
    }
    edge from parent node[prob,below] {$0.7$}
  };

% Beschriftung ohne scope
\node[text width=3.5cm, align=center] at ([yshift=1cm]PSC.north) {Wahrscheinlichkeit};
\node[font=\bfseries, text width=2.5cm, align=center] at ([yshift=1cm]SC.north) {$\Omega$};
\node[text width=2.5cm, align=center] at ([yshift=1cm]C1.north) {Krebs};
\node[text width=2.5cm, align=center] at ([yshift=1cm]S.north) {Rauchen};

\end{tikzpicture}

```


:::


### Wahrscheinlichkeitsbaum mit unabhängigen Variablen

::: {.callout-tip appearance="default"}
## Beispiel Münzwurf
Der Wahrscheinlichkeitsbaum für das Zufallsexperiment zwei Münzen zu werfen ist:

```{r}
#| label: probZreeMuenz
#| engine: tikz
\begin{tikzpicture}[
  grow'=right,
  level 1/.style ={level distance=2cm, sibling distance=1.6cm, parent anchor=east, child anchor=west},
  level 2/.style ={level distance=2cm, sibling distance=0.8cm},
  level 3/.style ={level distance=1.5cm, sibling distance=0.8cm, dashed},
  level 4/.style ={level distance=3cm, sibling distance=0.8cm, dashed},
  prob/.style={font=\footnotesize,above}
]

% Baumstruktur
\node (root) {}
  child {node (K1) {K}
    child {node (K2) {K}
      child {node (KK) {(K,K)}
        child {node (PKK) {$0.25$} edge from parent node[prob] {$0.5\cdot 0.5$}}
      }
      edge from parent node[prob] {$0.5$}
    }
    child {node (KZ) {Z}
      child {node (KZZ) {(K,Z)}
        child {node (PKZ) {$0.25$} edge from parent node[prob] {$0.5\cdot 0.5$}}
      }
      edge from parent node[prob,below] {$0.5$}
    }
    edge from parent node[prob,above] {$0.5$}
  }
  child {node (Z1) {Z}
    child {node (ZK) {K}
      child {node (ZKK) {(Z,K)}
        child {node (PZK) {$0.25$} edge from parent node[prob] {$0.5\cdot 0.5$}}
      }
      edge from parent node[prob] {$0.5$}
    }
    child {node (ZZ) {Z}
      child {node (ZZZ) {(Z,Z)}
        child {node (PZZ) {$0.25$} edge from parent node[prob] {$0.5\cdot 0.5$}}
      }
      edge from parent node[prob,below] {$0.5$}
    }
    edge from parent node[prob,below] {$0.5$}
  };

% Beschriftung ohne scope
\node[text width=3.5cm, align=center] at ([yshift=1cm]PKK.north) {Wahrscheinlichkeit};
\node[font=\bfseries, text width=2.5cm, align=center] at ([yshift=1cm]KK.north) {$\Omega$};
\node[text width=2.5cm, align=center] at ([yshift=1cm]K2.north) {Münze 2};
\node[text width=2.5cm, align=center] at ([yshift=1cm]K1.north) {Münze 1};

\end{tikzpicture}

```

:::


::: {.callout-tip appearance="default"}
## Beispiel mit 3 Variablen
In einer Population gibt es 40% Männer und 60% Frauen. Der Wahrscheinlichkeitsbaum für das Ziehen einer zufälligen Stichprobe von drei Personen ist unten dargestellt.

```{r}
#| engine: tikz
#| label: probTree3Vars
\begin{tikzpicture}[
  grow'=right,
  level 1/.style ={level distance=2cm, sibling distance=3.2cm, parent anchor=east, child anchor=west},
  level 2/.style ={level distance=2cm, sibling distance=1.6cm},
  level 3/.style ={level distance=2cm, sibling distance=0.8cm},
  level 4/.style ={level distance=1.5cm, sibling distance=0.8cm, dashed},
  level 5/.style ={level distance=3cm, sibling distance=0.8cm, dashed},
  prob/.style={font=\footnotesize,above}
]

\node (root) {}
  child {node (P1w) {w}
    child {node (P2w1) {w}
      child {node (P3w1) {w}
        child {node (www) {(w,w,w)}
          child {node (Pwww) {$0{,}216$} edge from parent node[prob] {$0{,}6\cdot 0{,}6\cdot 0{,}6$}}
        }
        edge from parent node[prob] {$0{,}6$}
      }
      child {node (P3m1) {m}
        child {node (wwm) {(w,w,m)}
          child {node (Pwwm) {$0{,}144$} edge from parent node[prob] {$0{,}6\cdot 0{,}6\cdot 0{,}4$}}
        }
        edge from parent node[prob,below] {$0{,}4$}
      }
      edge from parent node[prob] {$0{,}6$}
    }
    child {node (P2m1) {m}
      child {node (P3w2) {w}
        child {node (wmw) {(w,m,w)}
          child {node (Pwmw) {$0{,}144$} edge from parent node[prob] {$0{,}6\cdot 0{,}4\cdot 0{,}6$}}
        }
        edge from parent node[prob] {$0{,}6$}
      }
      child {node (P3m2) {m}
        child {node (wmm) {(w,m,m)}
          child {node (Pwmm) {$0{,}096$} edge from parent node[prob] {$0{,}6\cdot 0{,}4\cdot 0{,}4$}}
        }
        edge from parent node[prob,below] {$0{,}4$}
      }
      edge from parent node[prob,below] {$0{,}4$}
    }
    edge from parent node[prob,left] {$0{,}6$}
  }
  child {node (P1m) {m}
    child {node (P2w2) {w}
      child {node (P3w3) {w}
        child {node (mww) {(m,w,w)}
          child {node (Pmww) {$0{,}144$} edge from parent node[prob] {$0{,}4\cdot 0{,}6\cdot 0{,}6$}}
        }
        edge from parent node[prob] {$0{,}6$}
      }
      child {node (P3m3) {m}
        child {node (mwm) {(m,w,m)}
          child {node (Pmwm) {$0{,}096$} edge from parent node[prob] {$0{,}4\cdot 0{,}6\cdot 0{,}4$}}
        }
        edge from parent node[prob,below] {$0{,}4$}
      }
      edge from parent node[prob] {$0{,}6$}
    }
    child {node (P2m2) {m}
      child {node (P3w4) {w}
        child {node (mmw) {(m,m,w)}
          child {node (Pmmw) {$0{,}096$} edge from parent node[prob] {$0{,}4\cdot 0{,}4\cdot 0{,}6$}}
        }
        edge from parent node[prob] {$0{,}6$}
      }
      child {node (P3m4) {m}
        child {node (mmm) {(m,m,m)}
          child {node (Pmmm) {$0{,}064$} edge from parent node[prob] {$0{,}4\cdot 0{,}4\cdot 0{,}4$}}
        }
        edge from parent node[prob,below] {$0{,}4$}
      }
      edge from parent node[prob,below] {$0{,}4$}
    }
    edge from parent node[prob,left] {$0{,}4$}
  };

% Beschriftungen oben ohne scope
\node[text width=3.5cm, align=center] at ([yshift=1cm]Pwww.north) {Wahrscheinlichkeit};
\node[font=\bfseries, text width=2.5cm, align=center] at ([yshift=1cm]www.north) {$\Omega$};
\node[text width=2.5cm, align=center] at ([yshift=1cm]P3w1.north) {Person 3};
\node[text width=2.5cm, align=center] at ([yshift=1cm]P2w1.north) {Person 2};
\node[text width=2.5cm, align=center] at ([yshift=1cm]P1w.north) {Person 1};

\end{tikzpicture}

```

:::













## Satz von der vollständigen Wahrscheinlichkeit:

::: {.callout-warning appearance="default"}
##  Definition "Aufteilung des Wahrscheinlichkeitsraums"

Eine Menge von Ereignissen $A_1,A_2,\ldots,A_n$ aus demselben Ereignisraum $\Omega$
heißt eine *Aufteilung des Wahrscheinlichkeitsraums*, wenn sie die folgenden Bedingungen erfüllt:

1. Die Vereinigung der Ereignisse ist der Ereignisraum, das heißt, $A_1\cup \cdots\cup A_n =\Omega$
2. Alle Ereignisse sind paarweise ausschließend, das heißt  $A_i\cap A_j = \emptyset$ $\forall i\neq j$.

```{r}
#| label: fullProps
#| engine: tikz
\begin{tikzpicture}
\draw (0,3) node[anchor=north east] {$\Omega$} rectangle (4,0);
\foreach \x in {1,2,3} {
	\draw (\x,0) -- (\x,3);
} 
\node at (0.5,1.5) {$A_1$};
\node at (1.5,1.5) {$A_2$};
\node at (2.5,1.5) {$\cdots$};
\node at (3.5,1.5) {$A_n$};
\end{tikzpicture}
```

:::


Üblicherweise ist es einfach, eine Aufteilung des Wahrscheinlichkeitsraums zu erhalten, indem man eine Population entsprechend einer kategorischen Variable aufteilt, wie beispielsweise Geschlecht oder Blutgruppe usw.




 Wenn wir eine Aufteilung des Ereignisraums haben, können wir sie verwenden, um die Wahrscheinlichkeiten anderer Ereignisse in demselben Wahrscheinlichkeitsraum zu berechnen.

::: {.callout-warning appearance="default"}
## Definition "Gesamtwahrscheinlichkeit"
Gegeben eine Aufteilung $A_1,\ldots,A_n$  eines Wahrscheinlichkeitsraums $\Omega$, kann die Wahrscheinlichkeit jedes anderen Ereignisses $B$ des selben Wahrscheinlichkeitsraums mit der folgenden Formel berechnet werden:

$$
P(B) = \sum_{i=1}^n P(A_i\cap B) = \sum_{i=1}^n P(A_i)P(B|A_i).
$$

:::



::: {.callout-caution appearance="default"}
## Beweis

Der Beweis dieses Satzes ist recht einfach. Da  $A_1,\ldots,A_n$ eine Aufteilung von $\Omega$ ist, haben wir:

$$
B = B\cap \Omega = B\cap (A_1\cup \cdots \cup A_n) = (B\cap A_1)\cup \cdots \cup (B\cap A_n).
$$

Und alle Ereignisse dieser Vereinigung sind paarweise ausschließend, da $A_1,\ldots,A_n$. 
Daher gilt:

$$
\begin{aligned}
P(B) &= P((B\cap A_1)\cup \cdots \cup (B\cap A_n)) = P(B\cap A_1)+\cdots + P(B\cap A_n) =\\
&= P(A_1)P(B|A_1)+\cdots + P(A_n)P(B|A_n) = \sum_{i=1}^n P(A_i)P(B|A_i).
\end{aligned}
$$



```{r}
#| label: plotgesamtprob
# Basis-Plot vorbereiten
plot(NULL, xlim = c(0, 4), ylim = c(0, 3), type = "n", xlab = "", ylab = "", axes = FALSE, asp = 1)

# Rechteck für Omega
rect(0, 0, 4, 3, border = "black")
text(0, 3, expression(Omega), pos = 2)


# A_i Beschriftungen
text(0.5, 0.2, expression(A[1]))
text(1.5, 0.2, expression(A[2]))
text(2.5, 0.2, expression(cdots))
text(3.5, 0.2, expression(A[n]))

# Funktion zum Zeichnen einer gefüllten Ellipse
draw_filled_ellipse <- function(center.x, center.y, a, b, col = "skyblue", border = "black", n = 200) {
  t <- seq(0, 2*pi, length.out = n)
  x <- center.x + a * cos(t)
  y <- center.y + b * sin(t)
  polygon(x, y, col = col, border = border)
}

# Ellipse B (gefüllt mit Skyblue)
draw_filled_ellipse(2, 1.5, 1.9, 1, col = "skyblue")

# B-Beschriftung
text(2.5, 2.3, expression(B), cex=1.5)

# Funktion zum Füllen der Schnittbereiche A_i ∩ B
fill_intersection <- function(xmin, xmax, center.x, center.y, a, b, col = rgb(0.4, 0.6, 1, 0.3)) {
  t <- seq(0, 2*pi, length.out = 500)
  x <- center.x + a*cos(t)
  y <- center.y + b*sin(t)
  idx <- which(x >= xmin & x <= xmax)
  polygon(c(x[idx], rev(x[idx])), c(y[idx], rev(y[idx])), col = col, border = NA)
}

# Schnittbereiche füllen
fill_intersection(0, 1, 2, 1.5, 1.9, 1)
fill_intersection(1, 2, 2, 1.5, 1.9, 1)
fill_intersection(2, 3, 2, 1.5, 1.9, 1)
fill_intersection(3, 4, 2, 1.5, 1.9, 1)

# Beschriftungen der Schnittbereiche
text(0.6, 1.5, expression(A[1] %*% B), cex = 0.8)
text(1.5, 1.5, expression(A[2] %*% B), cex = 0.8)
text(2.5, 1.5, expression(cdots), cex = 0.8)
text(3.4, 1.5, expression(A[n] %*% B), cex = 0.8)

# Vertikale Trennlinien
abline(v = 1:3, col = "black")
```

:::




::: {.callout-tip appearance="default"}
## Beispiel: Diagnose

Ein Symptom $S$ kann durch eine Krankheit $K$ verursacht werden, kann aber auch bei Personen ohne die Krankheit auftreten. In einer Population beträgt der Anteil der Menschen mit der Krankheit 0,2. Es ist bekannt, dass 90 % der Personen mit der Krankheit das Symptom aufweisen, während nur 40 % der Personen ohne die Krankheit es haben.

Wie groß ist die Wahrscheinlichkeit, dass eine zufällig ausgewählte Person aus der Bevölkerung das Symptom hat?
:::

Um diese Frage zu beantworten, können wir den Satz von der vollständigen Wahrscheinlichkeit unter Verwendung der Aufteilung $\{K,\overline K\}$ anwenden:

$$
P(S) = P(K)P(S|K)+P(\overline K)P(S|\overline K) = 0.2\cdot 0.9 + 0.8\cdot 0.4 = 0.5.
$$
Das heißt, die Hälfte der Bevölkerung hat das Symptom. 

*Tatsächlich handelt es sich um einen gewichteten Mittelwert der Wahrscheinlichkeiten!*



::: {.callout-tip appearance="default"}
## Beispiel Wahrscheinlichkeitsbaum
Das Ergebnis der vorherigen Frage wird durch den Wahrscheinlichkeitsbaum des Wahrscheinlichkeitsraums noch klarer:

```{r}
#| label: krankheitsbaum
#| engine: tikz
\begin{tikzpicture}[
  grow'=right,
  level 1/.style ={level distance=2cm, sibling distance=1.6cm, parent anchor=east, child anchor=west},
  level 2/.style ={level distance=2cm, sibling distance=0.8cm},
  level 3/.style ={level distance=1.5cm, sibling distance=0.8cm, dashed},
  level 4/.style ={level distance=3cm, sibling distance=0.8cm, dashed},
  prob/.style={font=\footnotesize,above}
]

% Baumstruktur
\node (root) {}
  child {node (krank) {K}
    child {node (symptom_krank) {S}
      child {node[red] (ks) {$\text{K}, \text{S}$}
        child {node[red] (ksval) {$0{,}18$} edge from parent node[prob] {$0{,}2 \cdot 0{,}9$}}
      }
      edge from parent node[prob] {$0{,}9$}
    }
    child {node (kein_symptom_krank) {$\overline S$}
      child {node (kns) {$\text{K}, \overline{\text{S}}$}
        child {node (knsval) {$0{,}02$} edge from parent node[prob] {$0{,}2 \cdot 0{,}1$}}
      }
      edge from parent node[prob,below] {$0{,}1$}
    }
    edge from parent node[prob] {$0{,}2$}
  }
  child {node (nicht_krank) {$\overline K$}
    child {node (symptom_gesund) {S}
      child {node[red] (nks) {$\overline{\text{K}}, \text{S}$}
        child {node[red] (nksval) {$0{,}32$} edge from parent node[prob] {$0{,}8 \cdot 0{,}4$}}
      }
      edge from parent node[prob] {$0{,}4$}
    }
    child {node (kein_symptom_gesund) {$\overline S$}
      child {node (nk_ns) {$\overline{\text{K}}, \overline{\text{S}}$}
        child {node (nk_ns_val) {$0{,}48$} edge from parent node[prob] {$0{,}8 \cdot 0{,}6$}}
      }
      edge from parent node[prob,below] {$0{,}6$}
    }
    edge from parent node[prob,below] {$0{,}8$}
  };

% Beschriftung oberhalb der Ebenen, ohne scope
\node[text width=3.5cm, align=center] at ([yshift=1cm]ksval.north) {Wahrscheinlichkeit};
\node[font=\bfseries, text width=2.5cm, align=center] at ([yshift=1cm]ks.north) {$\Omega$};
\node[text width=2.5cm, align=center] at ([yshift=1cm]symptom_krank.north) {Symptom};
\node[text width=2.5cm, align=center] at ([yshift=1cm]krank.north) {Krankheit};

\end{tikzpicture}

```

$$
\begin{aligned}
P(S) &= P(K\cap S) + P(\overline K\cap S) = P(K)\cdot P(S|K)+P(\overline K)\cdot P(S|\overline K)\\
& = 0.2\cdot 0.9+ 0.8\cdot 0.4 = 0.18 + 0.32 = 0.5.
\end{aligned}
$$
:::









## Satz von Bayes



